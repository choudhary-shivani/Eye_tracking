{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sentence_id', 'word_id', 'word', 'nFix', 'FFD', 'GPT', 'TRT',\n",
      "       'fixProp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from util.tagger import postagger\n",
    "\n",
    "loaded_data = pd.read_csv('training_data.csv')\n",
    "print(loaded_data.columns)\n",
    "a = lambda x: ' '.join(x['word'].to_list())\n",
    "sentence_data = loaded_data.groupby('sentence_id').apply(a)\n",
    "loaded_data['tag'] = (loaded_data['word'].apply(postagger))\n",
    "loaded_data.to_csv('pos_tagged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = loaded_data[['tag', 'fixProp']].groupby('tag').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixProp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(FW, X)</th>\n",
       "      <td>90.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(VBG, VERB)</th>\n",
       "      <td>88.238830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(VBN, VERB)</th>\n",
       "      <td>87.645624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(JJ, ADJ)</th>\n",
       "      <td>84.637315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(NNS, NOUN)</th>\n",
       "      <td>84.337317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fixProp\n",
       "tag                   \n",
       "(FW, X)      90.909091\n",
       "(VBG, VERB)  88.238830\n",
       "(VBN, VERB)  87.645624\n",
       "(JJ, ADJ)    84.637315\n",
       "(NNS, NOUN)  84.337317"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.nlargest(5, 'fixProp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn=[]; ant = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kill': {'v': ['kill', 'kill', 'stamp_out', 'kill', 'kill', 'kill', 'kill', 'kill', 'kill', 'kill', 'toss_off', 'kill', 'kill', 'kill', 'kill'], 'n': ['killing', 'kill'], 'a': [], 'r': []}}\n",
      "v ['kill' 'stamp_out' 'toss_off']\n",
      "n ['kill' 'killing']\n",
      "a []\n",
      "r []\n",
      "1.791759469228055\n",
      "{'kill': {'v': ['kill', 'kill', 'stamp_out', 'kill', 'kill', 'kill', 'kill', 'kill', 'kill', 'kill', 'toss_off', 'kill', 'kill', 'kill', 'kill'], 'n': ['killing', 'kill'], 'a': [], 'r': []}, 'run': {'v': ['run', 'scat', 'run', 'operate', 'run', 'run', 'function', 'range', 'campaign', 'play', 'run', 'tend', 'run', 'run', 'run', 'run', 'prevail', 'run', 'run', 'carry', 'run', 'guide', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'ply', 'hunt', 'race', 'move', 'melt', 'ladder', 'run'], 'n': ['run', 'test', 'footrace', 'streak', 'run', 'run', 'run', 'run', 'run', 'run', 'rivulet', 'political_campaign', 'run', 'discharge', 'run', 'run'], 'a': [], 'r': []}}\n",
      "v ['campaign' 'carry' 'function' 'guide' 'hunt' 'ladder' 'melt' 'move'\n",
      " 'operate' 'play' 'ply' 'prevail' 'race' 'range' 'run' 'scat' 'tend']\n",
      "n ['discharge' 'footrace' 'political_campaign' 'rivulet' 'run' 'streak'\n",
      " 'test']\n",
      "a []\n",
      "r []\n",
      "4.77912349311153\n",
      "{'kill': {'v': ['kill', 'kill', 'stamp_out', 'kill', 'kill', 'kill', 'kill', 'kill', 'kill', 'kill', 'toss_off', 'kill', 'kill', 'kill', 'kill'], 'n': ['killing', 'kill'], 'a': [], 'r': []}, 'run': {'v': ['run', 'scat', 'run', 'operate', 'run', 'run', 'function', 'range', 'campaign', 'play', 'run', 'tend', 'run', 'run', 'run', 'run', 'prevail', 'run', 'run', 'carry', 'run', 'guide', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'ply', 'hunt', 'race', 'move', 'melt', 'ladder', 'run'], 'n': ['run', 'test', 'footrace', 'streak', 'run', 'run', 'run', 'run', 'run', 'run', 'rivulet', 'political_campaign', 'run', 'discharge', 'run', 'run'], 'a': [], 'r': []}, 'die': {'v': ['die', 'die', 'die', 'fail', 'die', 'die', 'die', 'die', 'die', 'die', 'die'], 'n': ['die', 'die', 'die'], 'a': [], 'r': []}}\n",
      "v ['die' 'fail']\n",
      "n ['die']\n",
      "a []\n",
      "r []\n",
      "0.6931471805599453\n",
      "{'kill': {'v': ['kill', 'kill', 'stamp_out', 'kill', 'kill', 'kill', 'kill', 'kill', 'kill', 'kill', 'toss_off', 'kill', 'kill', 'kill', 'kill'], 'n': ['killing', 'kill'], 'a': [], 'r': []}, 'run': {'v': ['run', 'scat', 'run', 'operate', 'run', 'run', 'function', 'range', 'campaign', 'play', 'run', 'tend', 'run', 'run', 'run', 'run', 'prevail', 'run', 'run', 'carry', 'run', 'guide', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'ply', 'hunt', 'race', 'move', 'melt', 'ladder', 'run'], 'n': ['run', 'test', 'footrace', 'streak', 'run', 'run', 'run', 'run', 'run', 'run', 'rivulet', 'political_campaign', 'run', 'discharge', 'run', 'run'], 'a': [], 'r': []}, 'die': {'v': ['die', 'die', 'die', 'fail', 'die', 'die', 'die', 'die', 'die', 'die', 'die'], 'n': ['die', 'die', 'die'], 'a': [], 'r': []}, 'suffer': {'v': ['suffer', 'suffer', 'suffer', 'digest', 'suffer', 'suffer', 'hurt', 'suffer', 'suffer', 'suffer', 'suffer'], 'n': [], 'a': [], 'r': []}}\n",
      "v ['digest' 'hurt' 'suffer']\n",
      "n []\n",
      "a []\n",
      "r []\n",
      "1.0986122886681098\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "out={}\n",
    "names = [\"kill\", \"run\", \"die\", 'suffer']\n",
    "for name in names:\n",
    "    for synset in wordnet.synsets(name):\n",
    "       siml = (wordnet.synset(f).wup_similarity(synset)) \n",
    "\n",
    "    #    if siml > 0.1:\n",
    "\n",
    "       name_ = synset.lemmas()[0].name() \n",
    "\n",
    "    #    print(out.keys())\n",
    "       if name not in out.keys():\n",
    "            out[name] = {\n",
    "                    \"v\" : [],\n",
    "                    \"n\" : [],\n",
    "                    \"a\" : [],\n",
    "                    \"r\" : []  \n",
    "                   }\n",
    "\n",
    "       if synset.pos() == 'v':\n",
    "           out[name]['v'].append(name_)\n",
    "       elif synset.pos() == 'n':\n",
    "    #        print(siml, synset, synset.pos())\n",
    "           out[name]['n'].append(name_)  \n",
    "    #        print(out[name]['n'])\n",
    "       elif synset.pos() == 'a':\n",
    "           out[name]['a'].append(name_)           \n",
    "       elif synset.pos() == 'r':\n",
    "           out[name]['r'].append(name_)\n",
    "\n",
    "       for lemma in synset.lemmas():\n",
    "          syn.append(lemma)    #add the synonyms\n",
    "          if lemma.antonyms():    #When antonyms are available, add them into the list\n",
    "            ant.append(lemma.antonyms()[0].name())\n",
    "    # print('Synonyms: ' + str(syn))\n",
    "    # print('Antonyms: ' + str(ant))\n",
    "    print(out)\n",
    "    lval = 1\n",
    "    if len(out) >0:\n",
    "        for key, val in out[name].items():\n",
    "            length = len(np.unique(val))\n",
    "            if length > 0:\n",
    "                lval *= 1/length\n",
    "            print(key, np.unique(val))\n",
    "    print(-log(lval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'kill.v.01'; out = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
